apiVersion: v1
data:
  rke-kube-dns-addon: "\n---\napiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n
    \ name: kube-dns-autoscaler\n  namespace: kube-system\n  labels:\n    k8s-app:
    kube-dns-autoscaler\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app:
    kube-dns-autoscaler\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n
    \           nodeSelectorTerms:\n              - matchExpressions:\n                -
    key: beta.kubernetes.io/os\n                  operator: NotIn\n                  values:\n
    \                   - windows\n      serviceAccountName: kube-dns-autoscaler\n
    \     containers:\n      - name: autoscaler\n        image: rancher/cluster-proportional-autoscaler:1.0.0\n
    \       resources:\n            requests:\n                cpu: \"20m\"\n                memory:
    \"10Mi\"\n        command:\n          - /cluster-proportional-autoscaler\n          -
    --namespace=kube-system\n          - --configmap=kube-dns-autoscaler\n          -
    --target=Deployment/kube-dns\n          # When cluster is using large nodes(with
    more cores), \"coresPerReplica\" should dominate.\n          # If using small
    nodes, \"nodesPerReplica\" should dominate.\n          - --default-params={\"linear\":{\"coresPerReplica\":128,\"nodesPerReplica\":4,\"min\":1}}\n
    \         - --logtostderr=true\n          - --v=2\n---\napiVersion: v1\nkind:
    ServiceAccount\nmetadata:\n  name: kube-dns-autoscaler\n  namespace: kube-system\n
    \ labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode:
    Reconcile\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n
    \ name: system:kube-dns-autoscaler\nrules:\n  - apiGroups: [\"\"]\n    resources:
    [\"nodes\"]\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:
    [\"replicationcontrollers/scale\"]\n    verbs: [\"get\", \"update\"]\n  - apiGroups:
    [\"extensions\"]\n    resources: [\"deployments/scale\", \"replicasets/scale\"]\n
    \   verbs: [\"get\", \"update\"]\n  - apiGroups: [\"\"]\n    resources: [\"configmaps\"]\n
    \   verbs: [\"get\", \"create\"]\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n
    \ name: system:kube-dns-autoscaler\nsubjects:\n  - kind: ServiceAccount\n    name:
    kube-dns-autoscaler\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n
    \ name: system:kube-dns-autoscaler\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion:
    v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n
    \ labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode:
    Reconcile\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n
    \ name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n
    \   kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode:
    Reconcile\nspec:\n  # replicas: not specified here:\n  # 1. In order to make Addon
    Manager do not reconcile this replicas parameter.\n  # 2. Default is 1.\n  # 3.
    Will be tuned in real time if DNS horizontal auto-scaling is turned on.\n  strategy:\n
    \   rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n
    \   matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n
    \       k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod:
    ''\n    spec:\n      nodeSelector:\n      \n      affinity:\n        podAntiAffinity:\n
    \         preferredDuringSchedulingIgnoredDuringExecution:\n          - weight:
    100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n
    \                 - key: k8s-app\n                    operator: In\n                    values:
    [\"kube-dns\"]\n              topologyKey: kubernetes.io/hostname\n        nodeAffinity:\n
    \         requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n
    \             - matchExpressions:\n                - key: beta.kubernetes.io/os\n
    \                 operator: NotIn\n                  values:\n                    -
    windows\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator:
    \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n
    \         name: kube-dns\n          optional: true\n      containers:\n      -
    name: kubedns\n        image: rancher/k8s-dns-kube-dns:1.15.0\n        resources:\n
    \         # TODO: Set memory limits when we've profiled the container for large\n
    \         # clusters, then set request = limit to keep this container in\n          #
    guaranteed class. Currently, this container falls into the\n          # \"burstable\"
    category so the kubelet doesn't backoff from restarting it.\n          limits:\n
    \           memory: 170Mi\n          requests:\n            cpu: 100m\n            memory:
    70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n
    \           port: 10054\n            scheme: HTTP\n          initialDelaySeconds:
    60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold:
    5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n
    \           port: 8081\n            scheme: HTTP\n          # we poll on pod startup
    for the Kubernetes master service and\n          # only setup the /readiness HTTP
    server once that's available.\n          initialDelaySeconds: 3\n          timeoutSeconds:
    5\n        args:\n        - --domain=cluster.local.\n        - --dns-port=10053\n
    \       - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        -
    name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort:
    10053\n          name: dns-local\n          protocol: UDP\n        - containerPort:
    10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort:
    10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n
    \       - name: kube-dns-config\n          mountPath: /kube-dns-config\n      -
    name: dnsmasq\n        image: rancher/k8s-dns-dnsmasq-nanny:1.15.0\n        livenessProbe:\n
    \         httpGet:\n            path: /healthcheck/dnsmasq\n            port:
    10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds:
    5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n
    \       - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n
    \       - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n
    \       - --log-facility=-\n        - --server=/cluster.local/127.0.0.1#10053\n
    \       - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n
    \       ports:\n        - containerPort: 53\n          name: dns\n          protocol:
    UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol:
    TCP\n        # see: https://github.com/kubernetes/kubernetes/issues/29055 for
    details\n        resources:\n          requests:\n            cpu: 150m\n            memory:
    20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath:
    /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: rancher/k8s-dns-sidecar:1.15.0\n
    \       livenessProbe:\n          httpGet:\n            path: /metrics\n            port:
    10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds:
    5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n
    \       - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A\n
    \       - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A\n
    \       ports:\n        - containerPort: 10054\n          name: metrics\n          protocol:
    TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu:
    10m\n      dnsPolicy: Default  # Don't use cluster DNS.\n      serviceAccountName:
    kube-dns\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace:
    kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service:
    \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name:
    \"KubeDNS\"\nspec:\n  selector:\n    k8s-app: kube-dns\n  clusterIP: 10.43.0.10\n
    \ ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n
    \   port: 53\n    protocol: TCP"
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: rke-kube-dns-addon
  selfLink: /api/v1/namespaces/kube-system/configmaps/rke-kube-dns-addon
